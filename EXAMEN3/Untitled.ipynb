{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import signal, ndimage, misc\n",
    "import  matplotlib.pyplot as plt\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "'''\n",
    "References:\n",
    "    https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\n",
    "    http://homepages.inf.ed.ac.uk/rbf/AVINVERTED/STEREO/av5_siftf.pdf\n",
    "    https://www.ipol.im/pub/art/2014/82/article_lr.pdf\n",
    "'''\n",
    "\n",
    "DIAG = list(set(itertools.permutations([-1,-1,1,1,0,0], 2)))\n",
    "\n",
    "def is_extrema(x, y, down, mid, up):\n",
    "    # 26 comparaisons to check if the point is a extrema (min or max)\n",
    "    mymin = mymax = mid[x,y]\n",
    "    rootx, rooty = x, y\n",
    "    for xx, yy in DIAG:\n",
    "        x = rootx + xx\n",
    "        y = rooty + yy\n",
    "\n",
    "        # out of bounds\n",
    "        if x < 0 or y < 0 or x >= mid.shape[0] or y >= mid.shape[1]:\n",
    "            return False\n",
    "\n",
    "        mymin = min(down[x,y], mid[x,y], up[x,y], mymin)\n",
    "        mymax = max(down[x,y], mid[x,y], up[x,y], mymax)\n",
    "\n",
    "    # check if x is still the max or min\n",
    "    return mymin != mid[rootx,rooty] and mymax == mid[rootx,rooty]\n",
    "\n",
    "'''\n",
    "The keypoint features are defined in SIFT as the extrema of the normalized\n",
    "Laplacian scale-space \n",
    "'''\n",
    "def locate_extremum(infos):\n",
    "    for key in infos:\n",
    "        infos[key][\"kps\"] = []\n",
    "        pictures = infos[key][\"dog\"]\n",
    "        for idx in range(1, len(pictures) -1):\n",
    "            pic = pictures[idx]\n",
    "            h, w = pic.shape\n",
    "            for i in range(h):\n",
    "                for j in range(w):\n",
    "                    # If it is a local minimum or maximum\n",
    "                    if is_extrema(i,j, pictures[idx-1], pic,\n",
    "                                        pictures[idx+1]):\n",
    "\n",
    "                       value = pic[i,j]\n",
    "                       sup_pic, sub_pic= pictures[idx+1], pictures[idx-1]\n",
    "\n",
    "                       # Computing dx_matrix -> 3d gradient\n",
    "                       dx = (pic[i,j+1] - pic[i,j-1]) * .5 / 255\n",
    "                       dy = (pic[i+1,j] - pic[i-1,j]) * .5 / 255\n",
    "                       dt = (sup_pic[i,j]- sub_pic[i,j]) * .5 / 255\n",
    "                       dx_matrix = np.matrix([[dx],[dy],[dt]])\n",
    "\n",
    "                       # Computing Hessian matrix\n",
    "                       dxx = (pic[i,j+1] + pic[i,j-1] - 2 * value) / 255\n",
    "                       dyy = (pic[i+1,j] + pic[i-1,j] - 2 * value) / 255\n",
    "                       dtt  = (sup_pic[i,j] + sub_pic[i,j] - 2 * value) / 255\n",
    "                       dxy = (pic[i+1,j+1] - pic[i+1,j-1] - pic[i-1,j+1] + pic[i-1,j-1]) * 0.25  / 255\n",
    "                       dxt = (sup_pic[i,j+1] - sup_pic[i,j-1] - sub_pic[i,j+1] + sub_pic[i,j-1])* 0.25 / 255\n",
    "                       dyt = (sup_pic[i+1,j] - sup_pic[i-1,j] - sub_pic[i+1,j] + sub_pic[i-1,j]) * 0.25 / 255\n",
    "                       \n",
    "                       h1 = [dxx,dxy,dxt]\n",
    "                       h2 = [dxy,dyy,dyt]\n",
    "                       h3 = [dxt,dyt,dtt]\n",
    "                       hessian_matrix = np.matrix([h1,h2,h3])\n",
    "\n",
    "                       # Predict DoG value at subpixel extrema\n",
    "                       try:\n",
    "                           opt_X = -np.linalg.inv(hessian_matrix) @ dx_matrix\n",
    "                       except:\n",
    "                           continue\n",
    "                           \n",
    "                       # Low contrast extrema prunning\n",
    "                       p = np.absolute(value + .5 * (dx_matrix.T @ opt_X))\n",
    "                       detH2 = (dxx * dyy) - (dxy ** 2)\n",
    "                       traceH2 = dxx + dyy\n",
    "                       if p < .03 or detH2 <= 0 \\\n",
    "                           or (traceH2 ** 2) / detH2 > 12 \\\n",
    "                           or np.count_nonzero(opt_X < .5)  != 3:\n",
    "                           continue\n",
    "\n",
    "                       infos[key][\"kps\"].append((i,j))\n",
    "             \n",
    "# Show contours, approximation of laplacian\n",
    "def diff_gaussian(infos, show=False):\n",
    "    for key in infos:\n",
    "        infos[key][\"dog\"] = []\n",
    "        pictures = infos[key][\"gaussian\"]\n",
    "        for idx in range(1, len(pictures)):\n",
    "           pic1 = pictures[idx].astype('float64')\n",
    "           pic2 = pictures[idx-1].astype('float64')\n",
    "           pic_gauss = (pic1 - pic2)\n",
    "           infos[key][\"dog\"].append(pic_gauss)\n",
    "\n",
    "    if show:\n",
    "        j = 1\n",
    "        for key in infos:\n",
    "            for picture in infos[key][\"dog\"]:\n",
    "                plt.subplot(len(infos), len(infos[key][\"dog\"]), j)\n",
    "                plt.imshow(picture, cmap=\"gray\")\n",
    "                j += 1\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Creating linear scale space\n",
    "def scale_space(img, infos, show=False):\n",
    "    '''\n",
    "        s: number of pictures\n",
    "        k: constant factor for each adjacents scales\n",
    "    '''\n",
    "    \n",
    "    s = 5\n",
    "    nb_octave = 4\n",
    "    k = np.power(2, 1/(s-1))\n",
    "    std = np.sqrt(.5)\n",
    "    # The first picture is a upsampling\n",
    "    image = misc.imresize(img, 200, 'bilinear')\n",
    "    \n",
    "    for octave in range(1, nb_octave + 1):\n",
    "        infos[octave] = {\"gaussian\": [], \"std\": []}\n",
    "        infos[octave]['original'] = image\n",
    "        # Create scale space \n",
    "        for i in range(s):\n",
    "            new_std = std * np.power(k,i)\n",
    "            blurred = ndimage.filters.gaussian_filter(image, new_std)\n",
    "            infos[octave][\"std\"].append(new_std)\n",
    "            infos[octave][\"gaussian\"].append(blurred)\n",
    "         \n",
    "        # Updating std\n",
    "        std = std * np.power(k, 2) \n",
    "        \n",
    "        # Resizing the picture\n",
    "        image = misc.imresize(image, 50, 'bilinear') \n",
    "        \n",
    "    if show:\n",
    "        for key in infos:\n",
    "            j = 1\n",
    "            for blurred_image in infos[key][\"gaussian\"]:\n",
    "                plt.subplot(1, s, j)\n",
    "                plt.imshow(blurred_image, cmap=\"gray\")\n",
    "                j += 1\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def run(img):\n",
    "    infos = {}\n",
    "    scale_space(img, infos)\n",
    "    diff_gaussian(infos)\n",
    "    locate_extremum(infos)\n",
    "    return infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "'''\n",
    "References:\n",
    "    http://aishack.in/tutorials/sift-scale-invariant-feature-transform-keypoint-orientation/\n",
    "    http://www.vlfeat.org/api/sift.html\n",
    "'''\n",
    "\n",
    "'''\n",
    "    infos: dict_keys([1, 2, 3, 4])\n",
    "    infos[1]: dict_keys(['original', 'gaussian', 'std' , 'dog', 'kps'])\n",
    "    \n",
    "    infos[1][\"gaussian\"] = [img0, img1...]\n",
    "    infos[1][\"kps\"] = [tuple, tuple1...]\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "    The size of the \"orientation collection region\" around the keypoint depends\n",
    "    on\n",
    "    it's scale. The bigger the scale, the bigger the collection region.\n",
    "'''\n",
    "\n",
    "### Compute gradient magnitude\n",
    "def gradient_m(i,j, picture):\n",
    "    ft = (picture[i,j+1] - picture[i,j-1]) ** 2\n",
    "    st = (picture[i+1,j] - picture[i-1,j]) ** 2\n",
    "\n",
    "    return np.sqrt(ft + st)\n",
    "\n",
    "### Compute gradient orientation\n",
    "def gradient_theta(i,j,picture):\n",
    "    #To avoid error division by zero\n",
    "    eps = 1e-5\n",
    "    \n",
    "    ft = picture[i+1,j] - picture[i-1,j]\n",
    "    st = (picture[i,j+1] - picture[i,j-1]) + eps\n",
    "\n",
    "    ret = 180 + np.arctan2(ft, st)  * 180 / np.pi\n",
    "    return ret\n",
    "\n",
    "\n",
    "def dominant_hist(hist):\n",
    "    sorted_hist = np.argsort(hist, axis=0)[::-1]\n",
    "    max_hist = hist[sorted_hist[0]]\n",
    "    i = 1\n",
    "    while .8 * max_hist < hist[sorted_hist[i]]:\n",
    "        print(\"Dominant i arg {}\".format(i))\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def create_histogram(i,j,picture,std):\n",
    "    truncate = 4.0\n",
    "    kernel_size = 2 * int(std * truncate + .5) + 1\n",
    "    window  = list(range(-kernel_size, kernel_size + 1))\n",
    "\n",
    "    diag  = set(itertools.permutations(window, 2))\n",
    "    rooti, rootj = i,j\n",
    "    theta_list =  []\n",
    "\n",
    "    gaussian = multivariate_normal(mean=[i,j], cov=1.5*std)\n",
    "    orient_hist = np.zeros([36,1])\n",
    "    \n",
    "    for ii, jj in diag:\n",
    "        x = rooti + ii\n",
    "        y = rootj + jj\n",
    "        if x - 1 < 0 or y - 1 < 0 or x + 1 > picture.shape[0] - 1 \\\n",
    "            or y + 1 > picture.shape[1] -1:\n",
    "            continue\n",
    "        \n",
    "        # TODO: Warning the magnitude are really small\n",
    "        magnitude = gradient_m(x,y,picture)\n",
    "        weight =  magnitude * gaussian.pdf([x,y])\n",
    "\n",
    "        orientation = gradient_theta(x,y,picture)\n",
    "        bins_orientation = np.clip(orientation // 10, 0,35)\n",
    "\n",
    "        orient_hist[int(bins_orientation)] += weight\n",
    "\n",
    "    return orient_hist\n",
    "\n",
    "\n",
    "def assign_orientation(infos):\n",
    "    index = 0 \n",
    "    for octave in infos.keys():\n",
    "        kps = infos[octave]['kps']\n",
    "        std = infos[octave][\"std\"][index]\n",
    "        picture = infos[octave]['gaussian'][index].astype('float64')\n",
    "\n",
    "        for i, j in kps: \n",
    "            hist = create_histogram(i,j,picture,std)\n",
    "            dominant_hist(hist)\n",
    "        print(\"Next octave\")\n",
    "    return infos\n",
    "\n",
    "### Showing keypoints for the first octave's picture\n",
    "def show_keypoints(infos):\n",
    "    #pic = np.zeros(infos[1]['gaussian'][0].shape)\n",
    "    pic = infos[1]['gaussian'][0]\n",
    "    for x,y in infos[1]['kps']:\n",
    "        pic[x,y] = 255\n",
    "    \n",
    "    plt.imshow(pic, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def run(load=None, img=None):\n",
    "    infos = None\n",
    "    if load  is not None:\n",
    "        infos = pickle.load(open(load, \"rb\"))\n",
    "        assign_orientation(infos)\n",
    "        #show_keypoints(infos)\n",
    "    if img is not None:\n",
    "        infos = laplacian.run(img) \n",
    "    return infos \n",
    "\n",
    "def reload():\n",
    "    def step(path, name):\n",
    "        img = np.array(Image.open(path).convert('L'))\n",
    "        infos = run(img=img)\n",
    "        pickle.dump(infos, open(\"pickle/infos_{}.pickle\".format(name), \"wb\"))\n",
    "        \n",
    "    path_paris = 'paris.jpg'\n",
    "    path_cat = 'cat.jpg'\n",
    "    \n",
    "    step(path_paris, \"paris\")\n",
    "    step(path_cat, \"cat\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_paris = 'paris.jpg'\n",
    "    path_cat = 'cat.jpg'\n",
    "    img = np.array(Image.open(path_cat).convert('L'))\n",
    "    run()\n",
    "\n",
    "    #reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
